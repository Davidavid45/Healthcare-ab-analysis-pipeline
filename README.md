# Healthcare-ab-analysis-pipeline

## ğŸ“Œ Project Overview
This project demonstrates the ability to work with **DBT, Snowflake, and Airflow** to build a **healthcare claims data pipeline**. The goal was to **ingest, transform, and analyze** claims data while performing **A/B testing** on total paid amounts.

## ğŸš€ Technologies Used
- **DBT** â€“ For data transformation and modeling
- **Snowflake** â€“ As the cloud data warehouse
- **Airflow** â€“ For orchestrating and scheduling pipeline runs
- **Python (Snowpark)** â€“ For analytical processing in Snowflake
- **Pandas & SciPy** â€“ For statistical analysis in Jupyter Notebook

## ğŸ“‚ Project Structure
â”œâ”€â”€ ğŸ“‚ data_pipeline/
â”‚   â”œâ”€â”€ ğŸ“‚ models/
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ staging/              # Staging tables
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ intermediate/         # Intermediate transformations
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ marts/                # Final transformed data marts
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ dbt_project.yml       # DBT configuration
â”‚   â”œâ”€â”€ ğŸ“‚ seeds/                    # Seed data for DBT
â”‚   â”œâ”€â”€ ğŸ“‚ tests/                    # DBT tests
â”‚   â”œâ”€â”€ ğŸ“‚ macros/                   # Reusable DBT macros
â”‚
â”œâ”€â”€ ğŸ“‚ airflow_dags/                  # Airflow DAGs for ETL orchestration
â”‚   â”œâ”€â”€ ğŸ“„ dbt_dag.py                 # DAG that runs DBT models
â”‚   â”œâ”€â”€ ğŸ“‚ dependencies/              # Airflow dependencies
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                     # Jupyter Notebooks for analysis
â”‚   â”œâ”€â”€ ğŸ“„ A_B_ANALYSIS.ipynb          # A/B testing results
â”‚
â”œâ”€â”€ ğŸ“‚ sql_queries/                   # SQL queries for Snowflake
â”‚   â”œâ”€â”€ ğŸ“„ claims_analysis.sql        # SQL for claims transformations
â”‚
â””â”€â”€ ğŸ“„ README.md                      # Project documentation                        

â”œâ”€â”€ data_pipeline/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/             # Staging tables
â”‚   â”‚   â”œâ”€â”€ intermediate/        # Intermediate transformations
â”‚   â”‚   â”œâ”€â”€ marts/               # Final transformed data marts
â”‚   â”‚   â”œâ”€â”€ dbt_project.yml      # DBT configuration
â”‚   â”œâ”€â”€ seeds/                   # Seed data for DBT
â”‚   â”œâ”€â”€ tests/                   # DBT tests
â”‚   â”œâ”€â”€ macros/                   # Reusable DBT macros
â”‚
â”œâ”€â”€ airflow_dags/                # Airflow DAGs for ETL orchestration
â”‚   â”œâ”€â”€ dbt_dag.py               # DAG that runs DBT models
â”‚   â”œâ”€â”€ dependencies/            # Airflow dependencies
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter Notebooks for analysis
â”‚   â”œâ”€â”€ A_B_ANALYSIS.ipynb       # A/B testing results
â”‚
â”œâ”€â”€ sql_queries/                 # SQL queries for Snowflake
â”‚   â”œâ”€â”€ claims_analysis.sql      # SQL for claims transformations
â”‚
â””â”€â”€ README.md                    # Project documentation

## ğŸ“Š A/B Testing Analysis
**Objective:**  
The A/B test was conducted to evaluate the difference in **Total Paid Amounts** between **Group A and Group B**.

### Hypothesis:
- **Hâ‚€ (Null Hypothesis):** No significant difference between Group A and Group B.
- **Hâ‚ (Alternative Hypothesis):** A significant difference exists in Total Paid Amounts.

### Key Steps:
1. Loaded the **FACT_AB_TEST_DATA** table from Snowflake.
2. Performed **data exploration** and checked for missing values.
3. Used **Shapiro-Wilk test** to check for normality (data was not normally distributed).
4. Conducted **Mann-Whitney U test** (since data was non-parametric).
5. Visualized distributions using **box plots & histograms**.

#### **Results:**
- **p-value: 0.70** (Mann-Whitney U Test)
- No statistically significant difference between **Group A and Group B**.
